
# toot
# bsky - add configurator -- update
# archive.is  -- add into readme
test add single url

test using user level systemd instead of cron as better way to have environment

 

there's something that breaks when the image is bogus that needs to be debugged too.

* shaarli selector switch for multiple configs?
    - why not have multiple shaarli outputs? Did I fix this?
* incorporate some from newsbeuter-dangerzone
* test INBOUND wallabag - seems to be broken?
* Per feed output selectors (though that's gonna be a pain)
* Check that send exits cleanly if there's no articles !!
* Check parser doesn't choke if there's a newline at the end of the posts.db file
* If hashtags are in description or title, make first occurance a hashtag
* XMPP   OUT VIA BOT

#TODO - REWRITE ALL THIS 
- need to have 
single url 
--queue
--url
defaults to VALUE of url as LAST passed var
--dry-run
holy crap, I've got duplicate functions, moron


* (Optional) Call `rss_preprocessor.sh`.
* `agaetr_parse.py` to pull down new articles from feeds.
* `agaetr_send.sh` to send *a* post to the activated social media services

Seriously, once everything is set up, that's it. You'll probably want to 
put these into cronjobs. 

# lemmy
# any other open server socials worth posting to?
# Something like a "daily urls" post?
# better tagging
# incorporate some ai summary shit? Maybe for image ID? Still, ew.


DONE
# swap wayback to waybackpy via pipx - https://pypi.org/project/waybackpy/
#### incorporate adding these to the post
# archive.org - https://pypi.org/project/waybackpy/
# archive.is -  https://github.com/palewire/archiveis
# removal of the short blurb

SO OUR FLOW WILL HAVE TO BE
- if archive.is,
    do first, capture url
- if internet archive
    do second, capture url
    (shorten that url)
# bespoke it.  Can't fix everyone's issue.
